I changed my blind model to this:
GPA 10%
Test scores 10% 
Extracurriculars 30%
Essays 40%
Reccomendations 10%

Aware model:
Legacy status (child of alumni) 4%
Income level 10%
First-generation status 10%
Disability 7%
Geographic proximity (e.g., local preference) 9%

I added a lot of preference to these contexts for the aware model. I feel that these aditional variables 
that are part of the aware model are very important considerations, as such I increased their weight. 
I did not exclude any of these additional factors as I feel that all of them are important. 

I would add another feature discussing essay strength, because I feel that essay strength could provide added
context that could change acceptace preference, (prioritizing better essays over others). I would also add a variable
for extenuating circumstances, such as a student having to provide childcare to their younger siblings thought highschool
thereby limiting their ability to partake in Extracurriculars and could also impact their gpa. 

Applicants that had higher essay scores and Extracurriculars benefited more from my models. Specifically George Johnson benefited from 
my new blind model, and Alice Stark and Ishaan Singh did not benefit from my new blind model. 

Adding the aware model made Carlos Rivera, Fatima Al-Sayed, and George Johnson all benefit, by now accepting them. 

I think that adding income and first-generation does make this system more fair, because these students are potentialy not as well
equiped for college as others who have higher socio-economic class with parents with college degrees. 

I feel that the aware model is more fair. I think having an equitable accepting design leads to creating a fair acceptace procedure. 
By weighting and making these aware factors important it creates a system that is therefore not punishing to those who may not have 
access to as much help and resources as those who have higher socio-economic class. 

My algorithm is fairly transparent, include in the application process that this application process does includ DEI selection and then I 
feel that this algorithm is fully transparent. 

Yes I could clearly explain a rejection with this model, because we dont penalize for not having attributes in the aware category, and I feel
that this creates and equitable not equal model I feel that applicants are accepted on a fair weighted system. 

I would feel comfortable with this algorithm because I feel that I prioritize Extracurriculars and essays which are some of the most important 
attributes of an application. Also because I feel that the aware model is equitable and not unfairly assigning weight to certain attributes I feel 
that I would be ok with this model. 

The risks are that someone may lie or manipulate DEI attributes thereby giving themselves an unfair additional score. 

Real world parallels exists, Specifically for scholarships within the NMSU Honors college. I have been on the pannel who accepts applicants 
for three years now and I do in fact take into account these factors in the aware section, including others. 

This excercise reveals that their can likely be no fairness in algorithmic acceptance. Becuase this program will never be able to encapsulate an entire person it will never be truly fair. 


I really dont think that algorithms can every be truly fair, because of all the limitations I list above, alogirthms can never create fair outputs. It will only shift biases.


I think that fairness and accountability are hard to decided in a blanket statement, I think it depends on the purpose, institution, and subjects. However for me and in the scholarship selection that I did, I would put fairness as more important in automated decisions. 